{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"fpstreams","text":"<p>A robust, type-safe functional programming library for Python.</p> <p><code>fpstreams</code> brings the power of Java Streams, Rust Results, and JavaScript Array methods to Python. It provides a fluent interface for data processing, null safety, and error handling without the boilerplate, all while remaining fully typed for IDE autocompletion.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Fluent Streams: Lazy evaluation chains (<code>map</code>, <code>filter</code>, <code>reduce</code>, <code>zip</code>).</li> <li>Parallel Processing: Automatic multi-core distribution with <code>.parallel()</code>.</li> <li>Clean Code Syntax: Syntactic sugar like <code>.pick()</code> and <code>.filter_none()</code> to replace lambdas.</li> <li>Data Science Ready: Convert streams directly to Pandas DataFrames, NumPy arrays, or CSV/JSON files.</li> <li>Null Safety: <code>Option</code> to eliminate <code>None</code> checks.</li> <li>Error Handling: <code>Result</code> (Success/Failure) to replace ugly <code>try/except</code> blocks.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install fpstreams\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-basic","title":"1. Basic","text":"<p>Replace messy loops with clean, readable pipelines.</p> <pre><code>from fpstreams import Stream, Collectors\n\ndata = [\"apple\", \"banana\", \"cherry\", \"apricot\", \"blueberry\"]\n\n# Filter, transform, and group in one\nresult = (\n    Stream(data)\n    .filter(lambda s: s.startswith(\"a\") or s.startswith(\"b\"))\n    .map(str.upper)\n    .collect(Collectors.grouping_by(lambda s: s[0]))\n)\n# Output: {'A': ['APPLE', 'APRICOT'], 'B': ['BANANA', 'BLUEBERRY']}\n</code></pre>"},{"location":"#2-clean-code-shortcuts","title":"2. Clean Code Shortcuts","text":"<p>Stop writing repetitive lambdas for dictionaries.</p> <pre><code>users = [\n    {\"id\": 1, \"name\": \"Alice\", \"role\": \"admin\"},\n    {\"id\": 2, \"name\": \"Bob\", \"role\": None},\n    {\"id\": 3, \"name\": None, \"role\": \"user\"},\n]\n\nnames = (\n    Stream(users)\n    .pick(\"name\")      # Extract \"name\" key\n    .filter_none()     # Remove None values\n    .to_list()\n)\n# Output: [\"Alice\", \"Bob\"]\n</code></pre>"},{"location":"#3-parallel-processing","title":"3. Parallel Processing","text":"<p><code>fpstreams</code> can automatically distribute heavy workloads across all CPU cores using the <code>.parallel()</code> method. It uses an optimized Map-Reduce architecture to minimize memory usage.</p> <pre><code>import math\nfrom fpstreams import Stream\n\ndef heavy_task(x):\n    return math.factorial(5000)\n\n# Automatically uses all available CPU cores\nresults = (\n    Stream(range(1000))\n    .parallel()\n    .map(heavy_task)\n    .to_list()\n)\n</code></pre>"},{"location":"#4-data-science-io","title":"4. Data Science &amp; I/O","text":"<p>Seamlessly integrate with the scientific stack.</p> <pre><code># Quick statistics\nstats = Stream([1, 2, 3, 4, 5, 100]).describe()\n\n# Output: {'count': 6, 'sum': 115, 'mean': 19.16, 'min': 1, 'max': 100, ...}\n\n# Convert to Pandas\ndf = Stream(users).to_df()\n\n# Stream directly to file\nStream(users).to_csv(\"output.csv\")\nStream(users).to_json(\"output.json\")\n</code></pre>"},{"location":"#infinite-streams-lazy-evaluation","title":"Infinite Streams &amp; Lazy Evaluation","text":"<p>Process massive datasets efficiently. Operations are only executed when needed.</p> <pre><code>def infinite_counter():\n    n = 0\n    while True:\n        yield n\n        n += 1\n\n# Take only the first 10 even numbers\nevens = (\n    Stream(infinite_counter())\n    .filter(lambda x: x % 2 == 0)\n    .limit(10)\n    .to_list()\n)\n</code></pre>"},{"location":"#benchmark","title":"Benchmark","text":"<p>Comparison between standard streams and <code>fpstreams.parallel()</code> on a 4-core machine:</p> Task Sequential(s) Parallel(s) Speedup Heavy Calculation (Factorials) 24.7603 10.8182 2.29x I/O Simulation (Sleep) 2.0986 0.8405 2.50x Light Calculation (Multiplication) 0.0151 0.3796 0.04x <p>Note: Parallel streams have overhead. Use them for CPU-intensive tasks or slow I/O, not simple arithmetic.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<ul> <li><code>Stream</code>: The core wrapper for sequential data processing.</li> <li><code>ParallelStream</code>: A multi-core wrapper for heavy parallel processing.</li> <li><code>Option</code>: Null-safe container.</li> <li><code>Result</code>: Error-handling container.</li> <li><code>Collectors</code>: Accumulation utilities (grouping, joining, summary stats).</li> </ul>"},{"location":"#functional-coverage-roadmap","title":"Functional Coverage &amp; Roadmap","text":"<p><code>fpstreams</code> already provides composable pipelines, collectors, and Option/Result containers, and there are clear next steps for additional combinators and richer statistics. There is also a candidate path to accelerate expensive calculations using a Rust extension module while keeping the Python API unchanged. See Functional Coverage &amp; Roadmap for the full assessment.</p>"},{"location":"#licence","title":"Licence","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"roadmap/","title":"Functional Coverage &amp; Roadmap","text":"<p>This document captures how <code>fpstreams</code> applies functional programming concepts today, what gaps are worth filling next, and how Rust could accelerate expensive workloads while preserving the Python-first API.</p>"},{"location":"roadmap/#current-functional-programming-coverage","title":"Current Functional Programming Coverage","text":"<p><code>fpstreams</code> already embodies several FP staples:</p> <ul> <li>Composable pipelines via <code>Stream</code>/<code>ParallelStream</code> transformations such as <code>map</code>, <code>filter</code>, <code>flat_map</code>, <code>zip</code>, <code>scan</code>, <code>batch</code>, and <code>window</code>.</li> <li>Lazy evaluation in stream pipelines, with terminal operations like <code>collect</code>, <code>reduce</code>, <code>to_list</code>, and <code>count</code>.</li> <li>Functional helpers like <code>pipe</code>, <code>curry</code>, and <code>retry</code> for composition, currying, and robust async retries.</li> <li>Container types (<code>Option</code>, <code>Result</code>) that encode nullability and error handling in a functional style.</li> <li>Collectors that provide grouping, summarizing, partitioning, and mapping into aggregate results.</li> <li>Async and parallel variants to keep functional pipelines consistent across sync/async/CPU-bound workloads.</li> </ul>"},{"location":"roadmap/#potential-functional-additions","title":"Potential Functional Additions","text":"<p>If you want deeper FP ergonomics, these additions would keep the API aligned with the existing stream/collector style:</p> <ol> <li>Stream combinators</li> <li><code>partition(predicate)</code> \u2192 returns <code>(matches, non_matches)</code> without forcing collectors.</li> <li><code>chunk_by(key_fn)</code> \u2192 starts a new chunk when the key changes (useful for run-length-like grouping).</li> <li><code>distinct_by(key_fn)</code> \u2192 distinct with projection, complementing <code>distinct()</code>.</li> <li><code>take_until(predicate)</code> / <code>drop_until(predicate)</code> \u2192 common FP flow-control operations.</li> <li> <p><code>merge_sorted(other, key=None)</code> \u2192 stream-friendly merges for pre-sorted inputs.</p> </li> <li> <p>Collector extensions</p> </li> <li><code>median</code>, <code>percentile</code>, and <code>histogram</code> collectors for richer stats.</li> <li> <p><code>top_n</code> / <code>bottom_n</code> collectors to avoid full sorts for large datasets.</p> </li> <li> <p>Option/Result ergonomics</p> </li> <li> <p><code>zip</code>, <code>sequence</code>, and <code>traverse</code> helpers to combine <code>Option</code>/<code>Result</code> values across collections.</p> </li> <li> <p>Type-focused affordances</p> </li> <li><code>map_typed</code> / <code>filter_typed</code> variants or overloads that narrow types for better IDE guidance.</li> </ol> <p>These are additive and can remain optional, preserving the current API surface while giving power users more functional vocabulary.</p>"},{"location":"roadmap/#rust-acceleration-plan","title":"Rust Acceleration Plan","text":"<p>Certain operations are CPU-heavy or memory-sensitive and are prime candidates for a Rust extension module. The key is to keep Python ergonomics while enabling a fast-path for large data or numeric workloads.</p>"},{"location":"roadmap/#candidate-hotspots","title":"Candidate hotspots","text":"<ul> <li>Numeric collectors: <code>summarizing</code>, <code>summing</code>, <code>averaging</code>, quantiles.</li> <li>High-volume transforms: <code>map</code>/<code>filter</code>/<code>flat_map</code> on numeric streams.</li> <li>Windowing/scan: especially on large sequences of numeric data.</li> <li>Group-by and distinct for large datasets (hashing overhead in Python can be high).</li> <li>Parallel operations: a Rust-backed <code>parallel()</code> pipeline using <code>rayon</code> for consistent throughput.</li> </ul>"},{"location":"roadmap/#proposed-approach","title":"Proposed approach","text":"<ol> <li>Optional extension module</li> <li>Build a <code>fpstreams_rust</code> extension via <code>pyo3</code> + <code>maturin</code>.</li> <li> <p>Ship as an extra (e.g., <code>pip install fpstreams[fast]</code>) that preserves the pure-Python fallback.</p> </li> <li> <p>Stable Python API</p> </li> <li>Keep the public classes and method signatures unchanged.</li> <li> <p>Route to Rust fast-paths when the stream contains Rust-friendly types (e.g., numeric lists, NumPy arrays, or buffer protocol inputs).</p> </li> <li> <p>Interoperability strategy</p> </li> <li>Support Python iterables for compatibility, but add an optimized path for lists/tuples/arrays.</li> <li> <p>Use <code>PyBuffer</code>/NumPy views for zero-copy operations where possible.</p> </li> <li> <p>Incremental rollout</p> </li> <li>Start with collectors (<code>summarizing</code>, <code>summing</code>, <code>averaging</code>) and window/scan operations.</li> <li>Add parallel map/filter/reduce after functional parity is proven.</li> <li> <p>Gate by benchmarks to validate real-world wins.</p> </li> <li> <p>Testing &amp; CI</p> </li> <li>Add Python/Rust parity tests.</li> <li>Build wheels for major platforms in CI to keep installation friction low.</li> </ol> <p>This plan keeps <code>fpstreams</code> easy to install while unlocking a high-performance option for complex workloads.</p>"},{"location":"reference/async_stream/","title":"Stream API","text":""},{"location":"reference/async_stream/#fpstreams.AsyncStream","title":"<code>fpstreams.AsyncStream</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>AsyncStream Implementation. Wrapper around an AsyncIterator for processing I/O bound tasks.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Ensures underlying resources (like file handles) are closed.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.of","title":"<code>of(*elements)</code>  <code>staticmethod</code>","text":"<p>Creates a stream from a sequence of values. Usage: AsyncStream.of(1, 2, 3)</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.from_iterable","title":"<code>from_iterable(iterable)</code>  <code>staticmethod</code>","text":"<p>Creates a stream from a synchronous iterable (list, range, etc).</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.from_aiterable","title":"<code>from_aiterable(aiterable)</code>  <code>staticmethod</code>","text":"<p>Wraps an existing async iterable or generator.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.from_file","title":"<code>from_file(path, encoding='utf-8')</code>  <code>staticmethod</code>","text":"<p>Reads a file line-by-line asynchronously. Requires <code>aiofiles</code> to be installed.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.interval","title":"<code>interval(seconds)</code>  <code>staticmethod</code>","text":"<p>Emits an increasing integer counter every N seconds. Infinite stream.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.from_paginated","title":"<code>from_paginated(first_page_fetcher, next_page_fetcher, data_extractor, has_next)</code>  <code>staticmethod</code>","text":"<p>Stream from a paginated API.</p> <p>Parameters:</p> Name Type Description Default <code>first_page_fetcher</code> <code>Callable[[], Awaitable[Any]]</code> <p>Async func to get the first response.</p> required <code>next_page_fetcher</code> <code>Callable[[Any], Awaitable[Any]]</code> <p>Async func taking previous response to get next.</p> required <code>data_extractor</code> <code>Callable[[Any], Iterable[U]]</code> <p>Func extracting a list of items from the response.</p> required <code>has_next</code> <code>Callable[[Any], bool]</code> <p>Func checking if more pages exist.</p> required"},{"location":"reference/async_stream/#fpstreams.AsyncStream.map","title":"<code>map(mapper)</code>","text":"<p>Applies a synchronous function to each element.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.map_async","title":"<code>map_async(func)</code>","text":"<p>Maps elements to Coroutines/Awaitables. </p> <p>Returns a stream of PENDING tasks. Use .gather() to execute them.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.debounce","title":"<code>debounce(wait_ms)</code>","text":"<p>Drops items that arrive less than 'wait_ms' after the previous item. Useful for filtering high-frequency sensor data or event streams.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.concurrent","title":"<code>concurrent(limit)</code>","text":"<p>Sets the max number of concurrent tasks for the next .gather() call.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.unordered","title":"<code>unordered()</code>","text":"<p>Allows .gather() to yield results out-of-order (faster).</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.gather","title":"<code>gather()</code>","text":"<p>Executes pending coroutines generated by .map_async().</p> <p>Applies concurrency limits and ordering rules.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.timeout","title":"<code>timeout(seconds)</code>","text":"<p>Wraps pending coroutines in asyncio.wait_for with a timeout.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.to_list","title":"<code>to_list()</code>  <code>async</code>","text":"<p>Collects all elements into a list.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.for_each","title":"<code>for_each(func)</code>  <code>async</code>","text":"<p>Executes func for each element.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.to_file_async","title":"<code>to_file_async(path, encoding='utf-8')</code>  <code>async</code>","text":"<p>Writes elements to a file asynchronously.</p>"},{"location":"reference/async_stream/#fpstreams.AsyncStream.collect","title":"<code>collect(collector)</code>  <code>async</code>","text":"<p>Materializes the stream and applies a standard (sync) Collector.</p> <p>Example: await stream.collect(Collectors.to_list())</p>"},{"location":"reference/collectors/","title":"Collectors API","text":"<p>The <code>Collectors</code> class provides common reduction operations for <code>Stream.collect()</code>.</p>"},{"location":"reference/collectors/#fpstreams.Collectors","title":"<code>fpstreams.Collectors</code>","text":"<p>Common implementations of Collector operations.</p>"},{"location":"reference/collectors/#fpstreams.Collectors.grouping_by","title":"<code>grouping_by(classifier, downstream=None)</code>  <code>staticmethod</code>","text":"<p>Groups elements by a classification function.</p> <p>Parameters:</p> Name Type Description Default <code>classifier</code> <code>Callable[[T], K]</code> <p>Function to determine the key.</p> required <code>downstream</code> <code>Callable[[Iterable[T]], R] | None</code> <p>Optional collector to apply to the values of each group.         If None, defaults to to_list().</p> <code>None</code> Example <p>grouping_by(lambda x: len(x), downstream=Collectors.counting())</p>"},{"location":"reference/collectors/#fpstreams.Collectors.summarizing","title":"<code>summarizing(mapper)</code>  <code>staticmethod</code>","text":"<p>Returns a SummaryStatistics object (count, sum, min, average, max).</p>"},{"location":"reference/collectors/#fpstreams.Collectors.counting","title":"<code>counting()</code>  <code>staticmethod</code>","text":"<p>Counts the elements.</p>"},{"location":"reference/collectors/#fpstreams.Collectors.summing","title":"<code>summing(mapper)</code>  <code>staticmethod</code>","text":"<p>Sums the elements after mapping them.</p>"},{"location":"reference/collectors/#fpstreams.Collectors.averaging","title":"<code>averaging(mapper)</code>  <code>staticmethod</code>","text":"<p>Calculates the average.</p>"},{"location":"reference/collectors/#fpstreams.Collectors.mapping","title":"<code>mapping(mapper, downstream)</code>  <code>staticmethod</code>","text":"<p>Adapts a collector to accept elements of a different type. Useful inside grouping_by.</p> Example <p>grouping_by(user.department, mapping(user.salary, averaging()))</p>"},{"location":"reference/collectors/#fpstreams.Collectors.to_dict","title":"<code>to_dict(key_mapper, value_mapper)</code>  <code>staticmethod</code>","text":"<p>Collects elements into a Dictionary. Example: Stream(users).collect(to_dict(lambda u: u.id, lambda u: u.name))</p>"},{"location":"reference/collectors/#fpstreams.Collectors.partitioning_by","title":"<code>partitioning_by(predicate)</code>  <code>staticmethod</code>","text":"<p>Partitions elements into two lists based on a predicate. Returns a dict: {True: [matches], False: [non-matches]}</p>"},{"location":"reference/collectors/#fpstreams.Collectors.to_columns","title":"<code>to_columns()</code>  <code>staticmethod</code>","text":"<p>Transposes a list of dicts into a dict of lists. Handles missing keys by inserting None to ensure alignment.</p>"},{"location":"reference/functional/","title":"Functional Utilities","text":"<p>Helper functions for functional composition and currying.</p>"},{"location":"reference/functional/#fpstreams.functional","title":"<code>fpstreams.functional</code>","text":""},{"location":"reference/functional/#fpstreams.functional.curry","title":"<code>curry(func)</code>","text":"<p>Transforms a function that takes multiple arguments into a chain of functions. @curry def add(a, b): return a + b</p> <p>add(1)(2) # returns 3</p> Source code in <code>fpstreams\\functional.py</code> <pre><code>def curry(func: Callable) -&gt; Callable:\n    \"\"\"\n    Transforms a function that takes multiple arguments into a chain of functions.\n    @curry\n    def add(a, b): return a + b\n\n    add(1)(2) # returns 3\n    \"\"\"\n    @functools.wraps(func)\n    def curried(*args):\n        if len(args) &gt;= func.__code__.co_argcount:\n            return func(*args)\n        return lambda *more: curried(*(args + more))\n    return curried\n</code></pre>"},{"location":"reference/functional/#fpstreams.functional.pipe","title":"<code>pipe(value, *functions)</code>","text":"<p>Passes a value through a sequence of functions. pipe(x, f, g, h) is equivalent to h(g(f(x)))</p> Source code in <code>fpstreams\\functional.py</code> <pre><code>def pipe(value: T, *functions: Callable[[Any], Any]) -&gt; Any: # type: ignore\n    \"\"\"\n    Passes a value through a sequence of functions.\n    pipe(x, f, g, h) is equivalent to h(g(f(x)))\n    \"\"\"\n    return functools.reduce(lambda val, func: func(val), functions, value)\n</code></pre>"},{"location":"reference/functional/#fpstreams.functional.retry","title":"<code>retry(attempts=3, backoff=1.5, jitter=True, exceptions=(Exception,))</code>","text":"<p>Decorator to retry an async function upon failure.</p> Usage <p>@retry(attempts=3, backoff=2.0) async def fetch(url): ...</p> Source code in <code>fpstreams\\functional.py</code> <pre><code>def retry(\n    attempts: int = 3, \n    backoff: float = 1.5, \n    jitter: bool = True,\n    exceptions: Tuple[Type[Exception], ...] = (Exception,)\n) -&gt; Callable[[Callable[..., Awaitable[T]]], Callable[..., Awaitable[T]]]:\n    \"\"\"\n    Decorator to retry an async function upon failure.\n\n    Usage:\n        @retry(attempts=3, backoff=2.0)\n        async def fetch(url): ...\n\n        ### Or inline in a stream:\n        stream.map_async(retry(attempts=3)(fetch_func))\n    \"\"\"\n    def decorator(func: Callable[..., Awaitable[T]]) -&gt; Callable[..., Awaitable[T]]:\n        @functools.wraps(func)\n        async def wrapper(*args: Any, **kwargs: Any) -&gt; T:\n            current_delay = 1.0\n            last_exception = None\n\n            for attempt in range(attempts):\n                try:\n                    return await func(*args, **kwargs)\n                except exceptions as e:\n                    last_exception = e\n                    if attempt == attempts - 1:\n                        raise e\n\n                    # Calculate wait time\n                    wait = current_delay\n                    if jitter:\n                        wait += random.uniform(0, 0.1 * wait)\n\n                    await asyncio.sleep(wait)\n                    current_delay *= backoff\n\n            raise last_exception  # type: ignore\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"reference/functional/#fpstreams.functional.retry--or-inline-in-a-stream","title":"Or inline in a stream:","text":"<p>stream.map_async(retry(attempts=3)(fetch_func))</p>"},{"location":"reference/option/","title":"Option API","text":""},{"location":"reference/option/#fpstreams.Option","title":"<code>fpstreams.Option</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A container object which may or may not contain a non-null value. Replaces None checks.</p>"},{"location":"reference/option/#fpstreams.Option.empty","title":"<code>empty()</code>  <code>classmethod</code>","text":"<p>Returns an empty Option instance.</p>"},{"location":"reference/option/#fpstreams.Option.filter","title":"<code>filter(predicate)</code>","text":"<p>If a value is present and matches the given predicate, return an Option describing the value, otherwise return an empty Option.</p>"},{"location":"reference/option/#fpstreams.Option.flat_map","title":"<code>flat_map(mapper)</code>","text":"<p>If a value is present, apply the provided Option-bearing mapping function to it,  return that result, otherwise return an empty Option.</p>"},{"location":"reference/option/#fpstreams.Option.if_present","title":"<code>if_present(action)</code>","text":"<p>If a value is present, invokes the specified consumer with the value, otherwise does nothing.</p>"},{"location":"reference/option/#fpstreams.Option.is_empty","title":"<code>is_empty()</code>","text":"<p>Returns True if there is no value present, otherwise False.</p>"},{"location":"reference/option/#fpstreams.Option.is_present","title":"<code>is_present()</code>","text":"<p>Returns True if there is a value present, otherwise False.</p>"},{"location":"reference/option/#fpstreams.Option.map","title":"<code>map(mapper)</code>","text":"<p>If a value is present, apply the provided mapping function to it,  and if the result is non-null, return an Option describing the result.</p>"},{"location":"reference/option/#fpstreams.Option.of","title":"<code>of(value)</code>  <code>classmethod</code>","text":"<p>Returns an Option describing the given non-null value.</p>"},{"location":"reference/option/#fpstreams.Option.of_nullable","title":"<code>of_nullable(value)</code>  <code>classmethod</code>","text":"<p>Returns an Option describing the given value, if non-null, otherwise returns an empty Option.</p>"},{"location":"reference/option/#fpstreams.Option.or_else","title":"<code>or_else(other)</code>","text":"<p>Return the value if present, otherwise return other.</p>"},{"location":"reference/option/#fpstreams.Option.or_else_get","title":"<code>or_else_get(supplier)</code>","text":"<p>Return the value if present, otherwise invoke other and return the result of that invocation.</p>"},{"location":"reference/option/#fpstreams.Option.or_else_throw","title":"<code>or_else_throw(exception_supplier)</code>","text":"<p>Return the contained value, if present, otherwise throw an exception to be created by the provided supplier.</p>"},{"location":"reference/parallel/","title":"ParallelStream API","text":""},{"location":"reference/parallel/#fpstreams.ParallelStream","title":"<code>fpstreams.ParallelStream</code>","text":"<p>               Bases: <code>BaseStream[T]</code></p>"},{"location":"reference/parallel/#fpstreams.ParallelStream.__iter__","title":"<code>__iter__()</code>","text":"<p>Materializes the parallel results and returns an iterator. Allows: for item in Stream(data).parallel(): ...</p>"},{"location":"reference/parallel/#fpstreams.ParallelStream.batch","title":"<code>batch(size)</code>","text":"<p>Chunks the stream into lists of the given size inside the worker.</p>"},{"location":"reference/parallel/#fpstreams.ParallelStream.window","title":"<code>window(size, step=1)</code>","text":"<p>Sliding window view. Note: In parallel, this only slides within the assigned chunk.</p>"},{"location":"reference/parallel/#fpstreams.ParallelStream.to_async","title":"<code>to_async()</code>","text":"<p>Converts the parallel stream into an AsyncStream. Note: This materializes the parallel results first.</p>"},{"location":"reference/result/","title":"Result API","text":""},{"location":"reference/result/#fpstreams.Result","title":"<code>fpstreams.Result</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A container for a value that represents either a successful result (Success) or a failure (Failure).  Replaces try/except blocks in functional pipelines.</p>"},{"location":"reference/result/#fpstreams.Result.error","title":"<code>error</code>  <code>property</code>","text":"<p>Returns the exception if this is a Failure, otherwise None.</p>"},{"location":"reference/result/#fpstreams.Result.failure","title":"<code>failure(error)</code>  <code>classmethod</code>","text":"<p>Creates a failed Result.</p>"},{"location":"reference/result/#fpstreams.Result.flat_map","title":"<code>flat_map(mapper)</code>","text":"<p>If Success, returns the result of applying the mapper (which must return a Result). If Failure, returns the existing Failure.</p>"},{"location":"reference/result/#fpstreams.Result.get_or_else","title":"<code>get_or_else(default)</code>","text":"<p>Returns the value if Success, or the default value if Failure.</p>"},{"location":"reference/result/#fpstreams.Result.get_or_throw","title":"<code>get_or_throw()</code>","text":"<p>Returns the value if Success, otherwise raises the stored exception.</p>"},{"location":"reference/result/#fpstreams.Result.map","title":"<code>map(mapper)</code>","text":"<p>If Success, applies the mapper to the value. If Failure, returns the existing Failure (skips the mapper).</p>"},{"location":"reference/result/#fpstreams.Result.map_error","title":"<code>map_error(mapper)</code>","text":"<p>If Failure, allows you to transform the exception. If Success, does nothing.</p>"},{"location":"reference/result/#fpstreams.Result.of","title":"<code>of(func)</code>  <code>classmethod</code>","text":"<p>Executes the provided function.  Returns Success(value) if it works, or Failure(exception) if it crashes.</p>"},{"location":"reference/result/#fpstreams.Result.on_failure","title":"<code>on_failure(action)</code>","text":"<p>Executes action if Failure.</p>"},{"location":"reference/result/#fpstreams.Result.on_success","title":"<code>on_success(action)</code>","text":"<p>Executes action if Success.</p>"},{"location":"reference/result/#fpstreams.Result.success","title":"<code>success(value)</code>  <code>classmethod</code>","text":"<p>Creates a successful Result.</p>"},{"location":"reference/stream/","title":"Stream API","text":""},{"location":"reference/stream/#fpstreams.Stream","title":"<code>fpstreams.Stream</code>","text":"<p>               Bases: <code>BaseStream[T]</code></p>"},{"location":"reference/stream/#fpstreams.Stream.__init__","title":"<code>__init__(iterable, size_hint=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[T]</code> <p>The data source.</p> required <code>size_hint</code> <code>Optional[int]</code> <p>Known size of the stream. If None, we calculate it if possible.</p> <code>None</code>"},{"location":"reference/stream/#fpstreams.Stream.__iter__","title":"<code>__iter__()</code>","text":"<p>Allows the stream to be used in standard for-loops.</p>"},{"location":"reference/stream/#fpstreams.Stream.of","title":"<code>of(*elements)</code>  <code>staticmethod</code>","text":"<p>Creates a stream from a sequence of values. Usage: Stream.of(1, 2, 3, 4)</p>"},{"location":"reference/stream/#fpstreams.Stream.generate","title":"<code>generate(supplier)</code>  <code>staticmethod</code>","text":"<p>Creates an infinite stream by calling supplier() repeatedly.</p>"},{"location":"reference/stream/#fpstreams.Stream.iterate","title":"<code>iterate(seed, unary_op)</code>  <code>staticmethod</code>","text":"<p>Creates an infinite stream: seed, f(seed), f(f(seed))...</p>"},{"location":"reference/stream/#fpstreams.Stream.limit","title":"<code>limit(max_size)</code>","text":"<p>Optimized limit. Uses slicing if source is a list/tuple/range.</p>"},{"location":"reference/stream/#fpstreams.Stream.skip","title":"<code>skip(n)</code>","text":"<p>Optimized skip. Uses slicing if source is a list/tuple/range.</p>"},{"location":"reference/stream/#fpstreams.Stream.batch","title":"<code>batch(size)</code>","text":"<p>Chunks the stream into lists of size N.</p>"},{"location":"reference/stream/#fpstreams.Stream.window","title":"<code>window(size, step=1)</code>","text":"<p>Creates a sliding window over the stream.</p>"},{"location":"reference/stream/#fpstreams.Stream.scan","title":"<code>scan(identity, accumulator)</code>","text":"<p>Performs a cumulative reduction.</p>"},{"location":"reference/stream/#fpstreams.Stream.zip_longest","title":"<code>zip_longest(other, fillvalue=None)</code>","text":"<p>Zips with another iterable, filling missing values instead of stopping.</p>"},{"location":"reference/stream/#fpstreams.Stream.to_async","title":"<code>to_async()</code>","text":"<p>Converts this synchronous stream into an AsyncStream. Useful for switching from processing in memory to sending data over network.</p>"}]}